\section{Video-Deepfakes}\label{sec:video-deepfakes2}

Video-Deepfakes sind eine besondere Form von gefälschten Medieninhalten, bei denen Gesichtsbilder in Videos so manipuliert werden, dass sie authentisch erscheinen.
Diese Technologie hat erhebliche Auswirkungen auf die Bereiche Sicherheit, Verifikation und Social Engineering.
Im Folgenden werden verschiedene Methoden zur Erstellung von Video-Deepfakes beschrieben und ihre technischen Details, Unterschiede, Gemeinsamkeiten sowie Vor- und Nachteile diskutiert.

\subsection{Veraltete Methode: 3D Modellierung}\label{subsec:3d-modellierung}

Die frühe Methode zur Erstellung von Video-Deepfakes basierte auf der 3D-Modellierung.
Hierbei wird ein dreidimensionales Modell des Gesichts einer Person erstellt, das anschließend animiert und in ein Video eingefügt wird.

\textbf{Technische Details:}
\begin{itemize}
    \item Erstellung eines 3D-Gesichtsmodells durch Scannen oder Fotogrammetrie.
    \item Animierung des Modells basierend auf Zielausdrücken oder Bewegungsdaten.
    \item Einfügung des animierten Modells in das Zielvideo mithilfe von Tracking- und Rendering-Techniken.
\end{itemize}

\textbf{Vor- und Nachteile:}
\begin{itemize}
    \item \textbf{Vorteile:} Hohe Kontrolle über die Gesichtsausdrücke und -bewegungen, gute Qualität bei statischen Szenen.
    \item \textbf{Nachteile:} Hoher Aufwand bei der Modellierung und Animation, Schwierigkeiten bei der realistischen Darstellung von dynamischen Szenen und feinen Details \cite{Deepfakes-An-Overview}.
\end{itemize}

\textbf{Einsatz im Kontext von Social Engineering:} Aufgrund des hohen Aufwands und der technischen Expertise, die für die Erstellung benötigt wird, sind 3D-Modellierungs-Deepfakes weniger verbreitet in Social Engineering-Angriffen.
Außerdem müssen die neuronalen Netze auf jedes Ziel- sowie Quellgesicht mit einigen Daten (~Minuten Video) neu trainiert werden.
Deshalb und aus Gründen der Performance ist dieser Ansatz für Echtzeitanwendungen, wie Videoanrufen, nicht geeignet \cite{social-engineering-a-survey}.

\subsection{Generative Adversarial Networks (\glspl{gan})}\label{subsec:gans}

Mit dem Aufkommen von Generative Adversarial Networks (\glspl{gan}) hat sich die Erstellung von Deepfakes erheblich vereinfacht und verbessert.
\glspl{gan} bestehen aus zwei neuronalen Netzwerken, einem Generator und einem Diskriminator, die gegeneinander trainiert werden.\cite{Deepfakes-a-survey-and-introduction-to-the-topical-collection}

\textbf{Technische Details:}
\begin{itemize}
    \item Der \textbf{Generator} erzeugt Bilder, die versuchen, echte Bilder nachzuahmen.
    \item Der \textbf{Diskriminator} bewertet die Bilder des Generators und unterscheidet zwischen echten und generierten Bildern.
    \item Durch diesen Wettbewerb verbessert sich die Qualität der erzeugten Bilder stetig.
\end{itemize}

\textbf{Vor- und Nachteile:}
\begin{itemize}
    \item \textbf{Vorteile:} Hohe Qualität der erzeugten Bilder, Möglichkeit zur Erstellung realistischer und dynamischer Gesichtsausdrücke.
    \item \textbf{Nachteile:} Erfordert große Datenmengen und Rechenressourcen für das Training, anfällig für Artefakte und Unstimmigkeiten bei komplexen Bewegungen \cite{Deepfakes-An-Overview}.
\end{itemize}

\textbf{Einsatz im Kontext von Social Engineering:} \gls{gan}-basierte Deepfakes sind effektiver und leichter zu erstellen, was sie zu einem mächtigen Werkzeug für Angreifer im Bereich Social Engineering macht.
Sie können verwendet werden, um gefälschte Videos zu erstellen, die Vertrauen erwecken und die Opfer täuschen.
\glspl{gan} sind ebenfalls zu ineffizient in der Implementierung, um in Echtzeitanwendungen Gebrauch zu finden.

\subsection{\gls{fsgan} und FSGANv2}\label{subsec:fsgan}

Eine Weiterentwicklung der \gls{gan}-Technologie sind die Face Swapping \glspl{gan} (\gls{fsgan}) und ihre verbesserte Version, FSGANv2.
Diese Technologien sind speziell für das Gesichtstausch und die Gesichtsnachstellung entwickelt worden.

\textbf{Technische Details:}
\begin{itemize}
    \item \gls{fsgan} nutzt \glspl{gan}, um Gesichtszüge von einer Quelle auf ein Zielvideo zu übertragen, ohne dass eine explizite 3D-Modellierung erforderlich ist.
    \item FSGANv2 verbessert diese Methode durch bessere Algorithmen zur Anpassung der Gesichtsausdrücke und -bewegungen sowie durch die Verwendung von fortschrittlichen Netzwerktechniken, um die Konsistenz und Realismus zu erhöhen \cite{fsganv2}.
\end{itemize}

\textbf{Vor- und Nachteile:}
\begin{itemize}
    \item \textbf{Vorteile:} Sehr realistische Ergebnisse, weniger Training und Daten erforderlich im Vergleich zu reinen \glspl{gan}, bessere Anpassung an unterschiedliche Gesichtsausdrücke und Beleuchtungen.
    \item \textbf{Nachteile:} Trotz Verbesserungen immer noch anfällig für subtile Unstimmigkeiten, die bei genauer Betrachtung auffallen können \cite{face-swapping-and-reenactment}.
\end{itemize}

\textbf{Einsatz im Kontext von Social Engineering:} \gls{fsgan} und FSGANv2 sind äußerst effektiv für Social Engineering-Angriffe, da sie hochrealistische Deepfakes erstellen können, die schwer zu erkennen sind.
Sie können verwendet werden, um falsche Identitäten zu erstellen und Vertrauen zu gewinnen, was das Risiko und den potenziellen Schaden solcher Angriffe erhöht \cite{deepfacelab}.

\subsection{Gemeinsamkeiten und Unterschiede}\label{subsec:gemeinsamkeiten-unterschiede}

\textbf{Gemeinsamkeiten:}
\begin{itemize}
    \item Alle Methoden zielen darauf ab, realistische Fälschungen zu erstellen, die schwer zu erkennen sind.
    \item Nutzung von KI und maschinellem Lernen zur Verbesserung der Qualität und Realismus der erzeugten Videos.
\end{itemize}

\textbf{Unterschiede:}
\begin{itemize}
    \item 3D-Modellierung erfordert manuelle Arbeit und ist weniger flexibel bei dynamischen Szenen.
    \item \glspl{gan} und deren Weiterentwicklungen (\gls{fsgan}, FSGANv2) bieten automatisierte Lösungen mit höherer Qualität und Flexibilität.
    \item \gls{fsgan} und FSGANv2 sind speziell auf Gesichtsmanipulation optimiert und bieten bessere Ergebnisse bei der Anpassung an verschiedene Bedingungen\cite{Deepfakes-a-survey-and-introduction-to-the-topical-collection}.
\end{itemize}

Insgesamt zeigt sich, dass die Weiterentwicklung der Deepfake-Technologien, insbesondere durch \glspl{gan} und deren Spezialisierungen wie \gls{fsgan} und FSGANv2, erheblich zur Verbesserung der Qualität und Realismus beigetragen hat.
Dies stellt jedoch auch eine größere Bedrohung im Bereich des Social Engineering dar, da die Täuschungsabsicht hinter den erzeugten Medieninhalten immer schwerer zu durchschauen ist.

\section{Face Swapping vs. Reenactment}\label{sec:face-swapping-vs.-reenactment}
Es gibt verschiedene Techniken von Video Deepfakes, im Folgenden werden Face-Swapping, sowie Reenactment näher betrachtet.
Beide Varianten können mit den oben vorgestellten Möglichkeiten realisiert werden.
Es gibt Modelle die für einen von beiden Anwendungsfällen besser geeignet sind, grundlegend basieren aber heutige Modelle immer auf \glspl{gan}.

\subsection{Face Swapping}\label{subsec:face-swapping}
Face Swapping, eine weit verbreitete Technik innerhalb der Deepfake-Technologie, beinhaltet das Austauschen eines
Gesichts in einem Bild oder Video durch das Gesicht einer anderen Person.
Diese Methode hat insbesondere in den letzten Jahren erhebliche Fortschritte gemacht, vor allem durch die Entwicklung von \glspl{gan}.
Bei Face Swapping wird das Gesicht der Zielperson durch ein anderes Gesicht ersetzt, wobei Merkmale wie Hautfarbe,
Beleuchtung und Gesichtsausdrücke so angepasst werden, dass das Ergebnis möglichst realistisch wirkt.
Diese Technik findet vor allem Anwendung in der Gestaltungs- und Medienbranche.
Es können z.B. Gesichter von Schauspielern auf ihre Stuntdoubles gesetzt werden, um realistischere Stunt Szenen zu erzeugen.
Eine besondere Form des Face Swapping ersetzt speziell den Mund eines Schauspielers, um die Synchronisation in anderen Sprachen zu vereinfachen\cite{Deepfakes-An-Overview}.
In der Cyber-Security spielt diese Technik keine große Rolle, da nur das Gesicht ersetzt wird, müssen Dinge wie Hintergrund, Frisur und Kleidung selbst an die Zielperson angepasst werden.
Dieser Aufwand ist heutzutage nicht mehr nötig, da Reenactmentmodelle ähnlich gute Ergebnisse erzielen.

\subsection{Reenactment}\label{subsec:reenactment}
Reenactment, auch als Face Transfer oder Puppeteering bekannt, ist eine Technik, bei der die Gesichtsausdrücke und -bewegungen eines Ausgangsbildes oder -videos auf ein Zielbild oder -video übertragen werden.
Dies ermöglicht es, das Gesicht der Zielperson so zu manipulieren, dass es die gleichen Bewegungen und Ausdrücke wie das Ausgangsgesicht zeigt.
Diese Technik findet sich ebenfalls in der Filmbranche wieder, indem z.B. verstorbene oder anderweitig verhinderte Schauspieler trotzdem noch in Filmen oder Serien zu sehen sind.
Das vermutlich bekannteste Beispiel hierfür ist die Nutzung von Deepfake-Technologie, um die Charaktere Grand Moff Tarkin und Prinzessin Leia in ``Rogue One: A Star Wars Story'' realistischer darzustellen.
In der originalen Filmproduktion wurden von beiden Charakteren alte 3D-Modelle bzw. Facescans verwendet um mit herkömmlichen Animations- und Rendertechniken realisiert.
Durch den Einsatz von Face-Swapping und Reenactment wurden die visuellen Effekte dieser Charaktere von Fans so verbessert, dass sie natürlicher und lebensechter wirken als die ursprünglichen Effekte.
Dieses Beispiel zeigt die Vorteile vom Einsatz von Deepfakes in der Filmproduktion und erweitern die Möglichkeiten der Branche erheblich\cite{rouge-one-deepfake}.\\
Im Kontext von Cyber-Security sind die Anwendungsfälle offensichtlich.
Es können durch Reenactment Videos von einflussreichen Personen innerhalb von Firmen erstellt werden, um Phishing noch effektiver zu gestalten.
Außerdem können Videos von Personen des öffentlichen Lebens angefertigt werden in denen diese kontroverse Aussagen tätigen, um die öffentliche Meinung ins Negative zu ziehen.
Ein gutes Beispiel hierfür ist \href{https://www.youtube.com/watch?v=cQ54GDm1eL0}{``You Won’t Believe What Obama Say In This Video''}.\\
Vor allem durch den Einsatz von auf Performance spezialisierter \glspl{gan} können Videos nahezu in Echtzeit gefaked werden.
Für Social Engineering relevante Videomedien sind ohnehin Video-Calls -- dies hat zur Folge, dass ein Delay von wenigen Sekunden, sowie kleine Artefakte oder Bildrauschen nicht ins Gewicht fallen, da diese auch von der Streamingplattform ausgehen könnten.
Die Qualität der Deepfakes braucht also nicht auf filmreifen Niveau zu sein, um für Social Engineering brauchbar zu sein.
Dies hat zur Folge, dass schon mit wenig Aufwand und Wissen, eine großzahl von Personen solche Fakes erstellen können.
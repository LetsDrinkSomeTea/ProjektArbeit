\chapter{Kurzfassung}\label{ch:kurzfassung}

In den letzten Jahren haben technologische Fortschritte im Bereich der \gls{ki} und des maschinellen Lernens zu einer signifikanten Entwicklung in der digitalen Manipulation von Medien geführt.
Insbesondere Deepfakes, bei denen KI verwendet wird, um realistisch aussehende Bilder, Videos oder Audiodateien zu erstellen, die es so nie gegeben hat, haben die Aufmerksamkeit von Forschern, Sicherheitsexperten und der breiten Öffentlichkeit gleichermaßen erregt.
Diese Technologie, die ursprünglich zur Verbesserung von visuellen Effekten und für kreative Zwecke entwickelt wurde, hat sich mittlerweile zu einem potenten Werkzeug entwickelt, das auch für bösartige Zwecke missbraucht werden kann.

Deepfakes basieren auf komplexen Algorithmen wie Generative Adversarial Networks (GANs), die es ermöglichen, Gesichter in Videos nahtlos auszutauschen, Stimmen zu imitieren oder Personen in Szenarien darzustellen, die nie stattgefunden haben.
Diese Fähigkeit, die Realität auf eine Weise zu verzerren, die für das menschliche Auge oft schwer zu erkennen ist, birgt erhebliche Risiken für die Gesellschaft.
Von der Verbreitung von Fehlinformationen über politische Manipulationen bis hin zu Erpressungen und Identitätsdiebstahl – die Einsatzmöglichkeiten von Deepfakes sind vielfältig und gefährlich.

Gleichzeitig hat Social Engineering, die Kunst der Manipulation von Menschen, um vertrauliche Informationen zu erhalten oder bestimmte Aktionen auszulösen, eine neue Dimension erreicht.
Social Engineering nutzt gezielt psychologische Techniken, um das Vertrauen von Individuen zu gewinnen und sie dazu zu bringen, sicherheitsrelevante Fehler zu begehen.
In einer zunehmend digitalisierten Welt, in der persönliche und berufliche Interaktionen häufig online stattfinden, wird die Verbindung zwischen Social Engineering und digitalen Technologien immer enger.

Die Kombination von Deepfakes und Social Engineering stellt eine besonders gefährliche Bedrohung dar.
Angreifer können Deepfakes nutzen, um das Vertrauen ihrer Zielpersonen zu erschleichen oder deren Entscheidungen zu beeinflussen, indem sie manipulierte Inhalte einsetzen, die beispielsweise vertraute Gesichter oder Stimmen imitieren.
Solche Angriffe sind schwer zu erkennen und zu bekämpfen, da sie sowohl technisches Wissen als auch ein tiefes Verständnis menschlicher Verhaltensmuster erfordern.

In dieser Ausarbeitung werden verschiedene Technologien im Bereich Video- und Audio-Deepfakes beleuchtet und vorgestellt.
Sie werden in den Kontext von Social Engineering eingeordnet und praktisch angewendet, um beispielhafte Szenarien darzustellen